{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inherited from https://www.kaggle.com/kenkpixdev/ensemble-lgb-xgb-with-hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.IPBC74C7KURV7CB2PKT5Z5FNR3SIBV4J.gfortran-win_amd64.dll\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime as dt\n",
    "from typing import Tuple, List, Dict\n",
    "\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "from hyperopt.pyll.base import scope\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at  2021-02-19 20:49:08.728342\n"
     ]
    }
   ],
   "source": [
    "# main flow\n",
    "start_time = dt.datetime.now()\n",
    "print(\"Started at \", start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "in_kaggle = False\n",
    "\n",
    "\n",
    "def get_data_file_path(is_in_kaggle: bool) -> Tuple[str, str, str]:\n",
    "    train_path = ''\n",
    "    test_path = ''\n",
    "    sample_submission_path = ''\n",
    "\n",
    "    if is_in_kaggle:\n",
    "        # running in Kaggle, inside the competition\n",
    "        train_path = '../input/tabular-playground-series-feb-2021/train.csv'\n",
    "        test_path = '../input/tabular-playground-series-feb-2021/test.csv'\n",
    "        sample_submission_path = '../input/tabular-playground-series-jan-2021/sample_submission.csv'\n",
    "    else:\n",
    "        # running locally\n",
    "        train_path = 'data/train.csv'\n",
    "        test_path = 'data/test.csv'\n",
    "        sample_submission_path = 'data/sample_submission.csv'\n",
    "\n",
    "    return train_path, test_path, sample_submission_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get the training set and labels\n",
    "train_set_path, test_set_path, sample_subm_path = get_data_file_path(in_kaggle)\n",
    "\n",
    "train = pd.read_csv(train_set_path)\n",
    "test = pd.read_csv(test_set_path)\n",
    "target = train.target\n",
    "\n",
    "subm = pd.read_csv(sample_subm_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cat0</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>...</th>\n",
       "      <th>cont5</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881122</td>\n",
       "      <td>0.421650</td>\n",
       "      <td>0.741413</td>\n",
       "      <td>0.895799</td>\n",
       "      <td>0.802461</td>\n",
       "      <td>0.724417</td>\n",
       "      <td>0.701915</td>\n",
       "      <td>0.877618</td>\n",
       "      <td>0.719903</td>\n",
       "      <td>6.994023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.440011</td>\n",
       "      <td>0.346230</td>\n",
       "      <td>0.278495</td>\n",
       "      <td>0.593413</td>\n",
       "      <td>0.546056</td>\n",
       "      <td>0.613252</td>\n",
       "      <td>0.741289</td>\n",
       "      <td>0.326679</td>\n",
       "      <td>0.808464</td>\n",
       "      <td>8.071256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>0.914155</td>\n",
       "      <td>0.369602</td>\n",
       "      <td>0.832564</td>\n",
       "      <td>0.865620</td>\n",
       "      <td>0.825251</td>\n",
       "      <td>0.264104</td>\n",
       "      <td>0.695561</td>\n",
       "      <td>0.869133</td>\n",
       "      <td>0.828352</td>\n",
       "      <td>5.760456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>G</td>\n",
       "      <td>...</td>\n",
       "      <td>0.934138</td>\n",
       "      <td>0.578930</td>\n",
       "      <td>0.407313</td>\n",
       "      <td>0.868099</td>\n",
       "      <td>0.794402</td>\n",
       "      <td>0.494269</td>\n",
       "      <td>0.698125</td>\n",
       "      <td>0.809799</td>\n",
       "      <td>0.614766</td>\n",
       "      <td>7.806457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382600</td>\n",
       "      <td>0.705940</td>\n",
       "      <td>0.325193</td>\n",
       "      <td>0.440967</td>\n",
       "      <td>0.462146</td>\n",
       "      <td>0.724447</td>\n",
       "      <td>0.683073</td>\n",
       "      <td>0.343457</td>\n",
       "      <td>0.297743</td>\n",
       "      <td>6.868974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id cat0 cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8  ...     cont5     cont6  \\\n",
       "0   1    A    B    A    A    B    D    A    E    C  ...  0.881122  0.421650   \n",
       "1   2    B    A    A    A    B    B    A    E    A  ...  0.440011  0.346230   \n",
       "2   3    A    A    A    C    B    D    A    B    C  ...  0.914155  0.369602   \n",
       "3   4    A    A    A    C    B    D    A    E    G  ...  0.934138  0.578930   \n",
       "4   6    A    B    A    A    B    B    A    E    C  ...  0.382600  0.705940   \n",
       "\n",
       "      cont7     cont8     cont9    cont10    cont11    cont12    cont13  \\\n",
       "0  0.741413  0.895799  0.802461  0.724417  0.701915  0.877618  0.719903   \n",
       "1  0.278495  0.593413  0.546056  0.613252  0.741289  0.326679  0.808464   \n",
       "2  0.832564  0.865620  0.825251  0.264104  0.695561  0.869133  0.828352   \n",
       "3  0.407313  0.868099  0.794402  0.494269  0.698125  0.809799  0.614766   \n",
       "4  0.325193  0.440967  0.462146  0.724447  0.683073  0.343457  0.297743   \n",
       "\n",
       "     target  \n",
       "0  6.994023  \n",
       "1  8.071256  \n",
       "2  5.760456  \n",
       "3  7.806457  \n",
       "4  6.868974  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, encoder=None,\n",
    "               scaler=None, cols_to_drop=None,\n",
    "               cols_to_encode=None, cols_to_scale=None):\n",
    "    \"\"\"\n",
    "    Preprocess input data\n",
    "    :param df: DataFrame with data\n",
    "    :param encoder: encoder object with fit_transform method\n",
    "    :param scaler: scaler object with fit_transform method\n",
    "    :param cols_to_drop: columns to be removed\n",
    "    :param cols_to_encode: columns to be encoded\n",
    "    :param cols_to_scale: columns to be scaled\n",
    "    :return: DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    if encoder:\n",
    "        for col in cols_to_encode:\n",
    "            df[col] = encoder.fit_transform(df[col])\n",
    "\n",
    "    if scaler:\n",
    "        for col in cols_to_scale:\n",
    "            df[col] = scaler.fit_transform(df[col].values.reshape(-1, 1))\n",
    "\n",
    "    if cols_to_drop:\n",
    "        df = df.drop(cols_to_drop, axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['cat' + str(i) for i in range(10)]\n",
    "cont_cols = ['cont' + str(i) for i in range(14)]\n",
    "\n",
    "train = preprocess(train, encoder=LabelEncoder(), scaler=StandardScaler(),\n",
    "                  cols_to_drop=['id', 'target'], cols_to_encode=cat_cols,\n",
    "                  cols_to_scale=cont_cols)\n",
    "\n",
    "# encoder=LabelEncoder()\n",
    "test = preprocess(test, encoder=LabelEncoder(), scaler=StandardScaler(),\n",
    "                 cols_to_drop=['id'], cols_to_encode=cat_cols,\n",
    "                 cols_to_scale=cont_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleModel:\n",
    "    def __init__(self, params):\n",
    "        \"\"\"\n",
    "        LGB + XGB model\n",
    "        \"\"\"\n",
    "        self.lgb_params = params['lgb']\n",
    "        self.xgb_params = params['xgb']\n",
    "\n",
    "        self.lgb_model = LGBMRegressor(**self.lgb_params)\n",
    "        self.xgb_model = XGBRegressor(**self.xgb_params)\n",
    "\n",
    "    def fit(self, x, y, *args, **kwargs):\n",
    "        return (self.lgb_model.fit(x, y, *args, **kwargs),\n",
    "                self.xgb_model.fit(x, y, *args, **kwargs))\n",
    "\n",
    "    def predict(self, x, weights=[1.0, 1.0]):\n",
    "        \"\"\"\n",
    "        Generate model predictions\n",
    "        :param x: data\n",
    "        :param weights: weights on model prediction, first one is the weight on lgb model\n",
    "        :return: array with predictions\n",
    "        \"\"\"\n",
    "        return (weights[0] * self.lgb_model.predict(x) +\n",
    "                weights[1] * self.xgb_model.predict(x)) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_params = {\n",
    "    \"lgb\" : {\n",
    "        \"num_leaves\": scope.int(hp.quniform(\"num_leaves\", 31, 200, 1)),\n",
    "        \"max_depth\": scope.int(hp.quniform(\"max_depth\", 10, 24, 1)),\n",
    "        'learning_rate': hp.uniform('learning_rate', 0.01, 0.3),\n",
    "        'min_split_gain': hp.uniform('min_split_gain', 0, 1.0),\n",
    "        'min_child_samples': scope.int(hp.quniform(\"min_child_samples\", 2, 700, 1)),\n",
    "        \"subsample\": hp.uniform(\"subsample\", 0.2, 1.0),\n",
    "        \"colsample_bytree\": hp.uniform(\"colsample_bytree\", 0.5, 1.0),\n",
    "        'reg_alpha': hp.uniform('reg_alpha', 1e-5, 1.0),\n",
    "        'reg_lambda': hp.uniform('reg_lambda', 0, 50),\n",
    "        'n_jobs': -1,\n",
    "        'n_estimators': 2000},\n",
    "    'xgb': {\n",
    "        'max_depth': scope.int(hp.quniform('xgb.max_depth', 10, 24, 1)),\n",
    "        'learning_rate': hp.uniform('xgb.learning_rate', 0.01, 0.3),\n",
    "        'gamma': hp.uniform('xgb.gamma', 1, 10),\n",
    "        'min_child_weight': scope.int(hp.quniform('xgb.min_child_weight', 2, 700, 1)),\n",
    "        'n_estimators': 2000,\n",
    "        'colsample_bytree': hp.uniform('xgb.colsample_bytree', 0.5, 0.9),\n",
    "        'subsample': hp.uniform('xgb.subsample', 0.5, 1.0),\n",
    "        'reg_lambda': hp.uniform('xgb.reg_lambda', 0, 100),\n",
    "        'reg_alpha': hp.uniform('xgb.reg_alpha', 1e-5, 0.5),\n",
    "        'objective': 'reg:squarederror',\n",
    "        'tree_method': 'gpu_hist',\n",
    "        'n_jobs': -1}\n",
    "}\n",
    "\n",
    "def ensemble_search(params):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=22)\n",
    "\n",
    "    model = EnsembleModel(params)\n",
    "\n",
    "    evaluation = [(X_test, y_test)]\n",
    "\n",
    "    model.fit(X_train, y_train,\n",
    "              eval_set=evaluation, eval_metric='rmse',\n",
    "              early_stopping_rounds=100, verbose=False)\n",
    "\n",
    "    val_preds = model.predict(X_test)\n",
    "    rmse = mean_squared_error(y_test, val_preds, squared=False)\n",
    "\n",
    "    return {\"loss\": rmse, \"status\": STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [49:21<00:00, 29.62s/trial, best loss: 0.8424887913360436]\n"
     ]
    }
   ],
   "source": [
    "X = train.copy()\n",
    "y = target\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "best_hyperparams = fmin(fn=ensemble_search,\n",
    "                       space=ensemble_params,\n",
    "                       algo=tpe.suggest,\n",
    "                       max_evals=100,\n",
    "                       trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.5866279475208961,\n",
       " 'learning_rate': 0.03031232932494199,\n",
       " 'max_depth': 17.0,\n",
       " 'min_child_samples': 455.0,\n",
       " 'min_split_gain': 0.6860513483791865,\n",
       " 'num_leaves': 106.0,\n",
       " 'reg_alpha': 0.039739131441590844,\n",
       " 'reg_lambda': 36.97850445493069,\n",
       " 'subsample': 0.28472607257700644,\n",
       " 'xgb.colsample_bytree': 0.5039031209135206,\n",
       " 'xgb.gamma': 4.465092951581267,\n",
       " 'xgb.learning_rate': 0.05292640058060351,\n",
       " 'xgb.max_depth': 19.0,\n",
       " 'xgb.min_child_weight': 475.0,\n",
       " 'xgb.reg_alpha': 0.4070590572766408,\n",
       " 'xgb.reg_lambda': 60.00604592381073,\n",
       " 'xgb.subsample': 0.5561407886208866}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, RMSE: 0.8459683968064248\n",
      "Fold 2, RMSE: 0.8390819506770154\n",
      "Fold 3, RMSE: 0.837938733559432\n",
      "Fold 4, RMSE: 0.8453188622072112\n",
      "Fold 5, RMSE: 0.8426249571150686\n",
      "Fold 6, RMSE: 0.8459673623179603\n",
      "Fold 7, RMSE: 0.8426650796838433\n",
      "Fold 8, RMSE: 0.84368738733979\n",
      "Fold 9, RMSE: 0.8393808081654686\n",
      "Fold 10, RMSE: 0.8446753957022116\n",
      "Mean RMSE:  0.8427308933574424\n",
      "Training complete in 9m 19s\n"
     ]
    }
   ],
   "source": [
    "since = time.time()\n",
    "columns = train.columns\n",
    "\n",
    "ensemble_params = {\n",
    "    \"lgb\" : {\n",
    "        \"num_leaves\": 36,\n",
    "        \"max_depth\": 21,\n",
    "        'learning_rate': 0.049019854828962754,\n",
    "        'min_split_gain': 0.2579555416739361,\n",
    "        'min_child_samples': 500,\n",
    "        \"subsample\": 0.2595537456780356,\n",
    "        \"colsample_bytree\": 0.6203517996970486,\n",
    "        'reg_alpha': 0.33867231210286647,\n",
    "        'reg_lambda': 42.071411120949854,\n",
    "        'n_jobs': -1,\n",
    "        'n_estimators': 5000},\n",
    "    'xgb': {\n",
    "        'max_depth': 13,\n",
    "        'learning_rate': 0.020206705089028228,\n",
    "        'gamma': 3.5746731812451156,\n",
    "        'min_child_weight': 564,\n",
    "        'n_estimators': 5000,\n",
    "        'colsample_bytree': 0.5015940592112956,\n",
    "        'subsample': 0.6839489639112909,\n",
    "        'reg_lambda': 18.085502002853246,\n",
    "        'reg_alpha': 0.17532087359570606,\n",
    "        'objective': 'reg:squarederror',\n",
    "        'tree_method': 'gpu_hist',\n",
    "        'n_jobs': -1}\n",
    "}\n",
    "    \n",
    "preds = np.zeros(test.shape[0])\n",
    "kf = KFold(n_splits=10, random_state=22, shuffle=True)\n",
    "rmse = []\n",
    "n = 0\n",
    "\n",
    "for trn_idx, test_idx in kf.split(train[columns], target):\n",
    "\n",
    "    X_tr, X_val=train[columns].iloc[trn_idx], train[columns].iloc[test_idx]\n",
    "    y_tr, y_val=target.iloc[trn_idx], target.iloc[test_idx]\n",
    "\n",
    "    model = EnsembleModel(ensemble_params)\n",
    "\n",
    "    model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], early_stopping_rounds=100, verbose=False)\n",
    "\n",
    "    preds += model.predict(test[columns]) / kf.n_splits\n",
    "    rmse.append(mean_squared_error(y_val, model.predict(X_val), squared=False))\n",
    "    \n",
    "    print(f\"Fold {n+1}, RMSE: {rmse[n]}\")\n",
    "    n += 1\n",
    "\n",
    "\n",
    "print(\"Mean RMSE: \", np.mean(rmse))\n",
    "end_time = time.time() - since\n",
    "print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        end_time // 60, end_time % 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit prediction\n",
    "# public LB 0.84283\n",
    "subm['target'] = preds\n",
    "subm.to_csv(\"ensemble_model_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, RMSE: 0.846022716892975\n",
      "Fold 2, RMSE: 0.8389665485942602\n",
      "Fold 3, RMSE: 0.8379310034116687\n",
      "Fold 4, RMSE: 0.8458756233064536\n",
      "Fold 5, RMSE: 0.8425900432951002\n",
      "Fold 6, RMSE: 0.846136452488498\n",
      "Fold 7, RMSE: 0.8428657676629502\n",
      "Fold 8, RMSE: 0.8440328349496541\n",
      "Fold 9, RMSE: 0.8395218028480587\n",
      "Fold 10, RMSE: 0.8443435252134142\n",
      "Mean RMSE:  0.8428286318663032\n",
      "Training complete in 7m 5s\n"
     ]
    }
   ],
   "source": [
    "# Local optimization yielded another set of params as well as a little better local score -  best loss: 0.8424602223218137\n",
    "\n",
    "{'colsample_bytree': 0.5339822834488268,\n",
    " 'learning_rate': 0.0771637203923797,\n",
    " 'max_depth': 11.0,\n",
    " 'min_child_samples': 220.0,\n",
    " 'min_split_gain': 0.3863023853133569,\n",
    " 'num_leaves': 31.0,\n",
    " 'reg_alpha': 0.09731772459111021,\n",
    " 'reg_lambda': 32.70688372281866,\n",
    " 'subsample': 0.28103089889544786,\n",
    " 'xgb.colsample_bytree': 0.759562316680131,\n",
    " 'xgb.gamma': 3.5718242850438195,\n",
    " 'xgb.learning_rate': 0.02500010390975047,\n",
    " 'xgb.max_depth': 11.0,\n",
    " 'xgb.min_child_weight': 220.0,\n",
    " 'xgb.reg_alpha': 0.411312935999471,\n",
    " 'xgb.reg_lambda': 23.416049187691378,\n",
    " 'xgb.subsample': 0.570420767510636}\n",
    "\n",
    "since = time.time()\n",
    "columns = train.columns\n",
    "\n",
    "ensemble_params = {\n",
    "    \"lgb\" : {\n",
    "        \"num_leaves\": 31,\n",
    "        \"max_depth\": 11,\n",
    "        'learning_rate': 0.0771637203923797,\n",
    "        'min_split_gain': 0.3863023853133569,\n",
    "        'min_child_samples': 220,\n",
    "        \"subsample\": 0.28103089889544786,\n",
    "        \"colsample_bytree\": 0.5339822834488268,\n",
    "        'reg_alpha': 0.09731772459111021,\n",
    "        'reg_lambda': 32.70688372281866,\n",
    "        'n_jobs': -1,\n",
    "        'n_estimators': 5000},\n",
    "    'xgb': {\n",
    "        'max_depth': 11,\n",
    "        'learning_rate': 0.02500010390975047,\n",
    "        'gamma': 3.5718242850438195,\n",
    "        'min_child_weight': 220,\n",
    "        'n_estimators': 5000,\n",
    "        'colsample_bytree': 0.759562316680131,\n",
    "        'subsample': 0.570420767510636,\n",
    "        'reg_lambda': 23.416049187691378,\n",
    "        'reg_alpha': 0.411312935999471,\n",
    "        'objective': 'reg:squarederror',\n",
    "        'tree_method': 'gpu_hist',\n",
    "        'n_jobs': -1}\n",
    "}\n",
    "    \n",
    "preds = np.zeros(test.shape[0])\n",
    "kf = KFold(n_splits=10, random_state=22, shuffle=True)\n",
    "rmse = []\n",
    "n = 0\n",
    "\n",
    "for trn_idx, test_idx in kf.split(train[columns], target):\n",
    "\n",
    "    X_tr, X_val=train[columns].iloc[trn_idx], train[columns].iloc[test_idx]\n",
    "    y_tr, y_val=target.iloc[trn_idx], target.iloc[test_idx]\n",
    "\n",
    "    model = EnsembleModel(ensemble_params)\n",
    "\n",
    "    model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], early_stopping_rounds=100, verbose=False)\n",
    "\n",
    "    preds += model.predict(test[columns]) / kf.n_splits\n",
    "    rmse.append(mean_squared_error(y_val, model.predict(X_val), squared=False))\n",
    "    \n",
    "    print(f\"Fold {n+1}, RMSE: {rmse[n]}\")\n",
    "    n += 1\n",
    "\n",
    "\n",
    "print(\"Mean RMSE: \", np.mean(rmse))\n",
    "end_time = time.time() - since\n",
    "print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        end_time // 60, end_time % 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit prediction\n",
    "# public LB 0.84282\n",
    "subm['target'] = preds\n",
    "subm.to_csv(\"ensemble_model_3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are done. That is all, folks!\n",
      "Finished at  2021-02-19 21:55:00.454026\n",
      "Elapsed time:  1:05:51.725684\n"
     ]
    }
   ],
   "source": [
    "print('We are done. That is all, folks!')\n",
    "finish_time = dt.datetime.now()\n",
    "print(\"Finished at \", finish_time)\n",
    "elapsed = finish_time - start_time\n",
    "print(\"Elapsed time: \", elapsed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
